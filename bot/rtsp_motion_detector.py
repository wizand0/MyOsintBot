# rtsp_motion_detector.py
import cv2
import csv
import os
import time
import json
import logging
import io
import shutil
from ultralytics import YOLO
from bot.config import ADMIN_ID

# ===================== ÐÐÐ¡Ð¢Ð ÐžÐ™ÐšÐ˜ =====================
SENSITIVITY = 25
MIN_AREA = 800
PLAYBACK_SPEED = 8
SAVE_FRAMES = True
RECOGNITION_DELAY_SEC = 4
OUTPUT_FILE = "rtsp_motions_log.csv"
FRAMES_DIR = "rtsp_motion_frames"
YOLO_MODEL = "yolov8n.pt"
CONF_THRESHOLD = 0.7
TARGET_CLASSES = ["person", "cat", "dog"]

# Ð›Ð¾Ð³Ð³ÐµÑ€
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s",
    handlers=[logging.StreamHandler()]
)

os.makedirs(FRAMES_DIR, exist_ok=True)

# ===================== Ð£Ñ‚Ð¸Ð»Ð¸Ñ‚Ñ‹ =====================
def now_ts():
    return time.strftime("%Y-%m-%d %H:%M:%S")

def date_dir():
    d = time.strftime("%Y%m%d")
    p = os.path.join(FRAMES_DIR, d)
    os.makedirs(p, exist_ok=True)
    return p

# ===================== ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÐµÐ¹ =====================
def check_dependencies(bot=None):
    """ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ðµ ffmpeg Ð¸ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÑƒ Ð² OpenCV"""
    errors = []
    if shutil.which("ffmpeg") is None:
        errors.append("âŒ ffmpeg Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ð² ÐºÐ¾Ð½Ñ‚ÐµÐ¹Ð½ÐµÑ€Ðµ")

    build_info = cv2.getBuildInformation()
    if "FFMPEG" not in build_info:
        errors.append("âŒ OpenCV ÑÐ¾Ð±Ñ€Ð°Ð½ Ð±ÐµÐ· Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ¸ ffmpeg")

    if errors:
        for e in errors:
            logging.error(e)
        if bot:
            for e in errors:
                try:
                    bot.loop.create_task(bot.send_message(chat_id=ADMIN_ID, text=e))
                except Exception:
                    pass
    else:
        logging.info("âœ… ffmpeg Ð¸ OpenCV Ð² Ð¿Ð¾Ñ€ÑÐ´ÐºÐµ")

# ===================== YOLO =====================
logging.info("ðŸ“¦ Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ YOLOv8...")
model = YOLO(YOLO_MODEL)

if not os.path.exists(OUTPUT_FILE):
    with open(OUTPUT_FILE, "w", newline="", encoding="utf-8") as f:
        csv.writer(f).writerow(["camera", "timestamp", "class", "confidence"])

# ===================== ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ =====================
async def run_rtsp_detector(bot, enabled_flag: callable):
    """ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ Ñ‚Ð¾Ñ‡ÐºÐ° Ð²Ñ…Ð¾Ð´Ð°"""
    check_dependencies(bot)

    with open("cameras.json", "r", encoding="utf-8") as c:
        cameras = json.load(c)
    if not cameras:
        logging.error("âŒ cameras.json Ð¿ÑƒÑÑ‚Ð¾Ð¹.")
        return

    logging.info(f"ðŸ” ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ {len(cameras)} ÐºÐ°Ð¼ÐµÑ€. Ð—Ð°Ð¿ÑƒÑÐº Ð°Ð½Ð°Ð»Ð¸Ð·Ð°...")

    for name, url in cameras.items():
        await detect_motion_and_objects(bot, name, url, enabled_flag)


async def detect_motion_and_objects(bot, camera_name, rtsp_url, enabled_flag):
    logging.info(f"â–¶ï¸ ÐŸÐ¾Ð´ÐºÐ»ÑŽÑ‡Ð°ÑŽÑÑŒ Ðº {camera_name} ({rtsp_url})...")
    cap = cv2.VideoCapture(rtsp_url, cv2.CAP_FFMPEG)
    if not cap.isOpened():
        logging.error(f"âŒ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒÑÑ Ðº {camera_name}")
        return

    logging.info(f"âœ… Ð¡Ð¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ Ñ {camera_name} ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾")

    ret, frame1 = cap.read()
    ret2, frame2 = cap.read()
    if not ret or not ret2:
        logging.error(f"âŒ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ñ€Ð¾Ñ‡Ð¸Ñ‚Ð°Ñ‚ÑŒ Ð½Ð°Ñ‡Ð°Ð»ÑŒÐ½Ñ‹Ðµ ÐºÐ°Ð´Ñ€Ñ‹ {camera_name}")
        cap.release()
        return

    last_trigger_time = 0.0
    frame_count = 0

    try:
        while True:
            if not enabled_flag():
                logging.info(f"â¹ ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÑŽ {camera_name}, Ð¾ÑÐ²Ð¾Ð±Ð¾Ð¶Ð´Ð°ÑŽ Ð¿Ð¾Ñ‚Ð¾Ðº")
                cap.release()
                await bot.send_message(chat_id=ADMIN_ID, text=f"â¹ {camera_name}: Ð¿Ð¾Ñ‚Ð¾Ðº Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½")
                break

            if frame_count % PLAYBACK_SPEED != 0:
                frame1 = frame2
                if not cap.grab():
                    logging.warning(f"âš ï¸ grab() Ð²ÐµÑ€Ð½ÑƒÐ» False Ð´Ð»Ñ {camera_name}")
                    break
                ok, frame2 = cap.retrieve()
                if not ok:
                    logging.warning(f"âš ï¸ retrieve() Ð²ÐµÑ€Ð½ÑƒÐ» False Ð´Ð»Ñ {camera_name}")
                    break
                frame_count += 1
                continue

            # ÐÐ½Ð°Ð»Ð¸Ð· Ð´Ð²Ð¸Ð¶ÐµÐ½Ð¸Ñ
            small1 = cv2.resize(frame1, (640, 360))
            small2 = cv2.resize(frame2, (640, 360))
            diff = cv2.absdiff(small1, small2)
            gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)
            blur = cv2.GaussianBlur(gray, (5, 5), 0)
            _, thresh = cv2.threshold(blur, SENSITIVITY, 255, cv2.THRESH_BINARY)
            dilated = cv2.dilate(thresh, None, iterations=3)
            contours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
            motion_detected = any(cv2.contourArea(c) >= MIN_AREA for c in contours)

            if motion_detected:
                logging.info(f"ðŸš¨ Ð”Ð²Ð¸Ð¶ÐµÐ½Ð¸Ðµ Ð·Ð°Ñ„Ð¸ÐºÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð¾ Ð½Ð° {camera_name}")
                results = model(frame2, verbose=False)[0]
                for box in results.boxes:
                    cls_id = int(box.cls[0])
                    class_name = results.names[cls_id]
                    conf = float(box.conf[0])

                    if class_name in TARGET_CLASSES and conf >= CONF_THRESHOLD:
                        now = time.time()
                        if (now - last_trigger_time) >= RECOGNITION_DELAY_SEC:
                            ts = now_ts()
                            logging.info(f"âœ… {camera_name}: {class_name} ({conf:.2f}), {ts}")

                            _, buf = cv2.imencode(".jpg", frame2)
                            image_bytes = io.BytesIO(buf)
                            await bot.send_photo(
                                chat_id=ADMIN_ID,
                                photo=image_bytes,
                                caption=f"{camera_name}: {class_name} ({conf:.2f}) {ts}"
                            )

                            if SAVE_FRAMES:
                                fname = f"{camera_name}_{ts.replace(':', '-')}_{class_name}.jpg"
                                cv2.imwrite(os.path.join(date_dir(), fname), frame2)

                            with open(OUTPUT_FILE, "a", newline="", encoding="utf-8") as f:
                                csv.writer(f).writerow([camera_name, ts, class_name, f"{conf:.2f}"])

                            last_trigger_time = now
                        break

            frame1 = frame2
            if not cap.grab():
                break
            ok, frame2 = cap.retrieve()
            if not ok:
                break
            frame_count += 1

    except Exception as e:
        logging.exception(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ {camera_name}: {e}")
    finally:
        cap.release()
        logging.info(f"ðŸ”š ÐŸÐ¾Ñ‚Ð¾Ðº {camera_name} Ð·Ð°Ð²ÐµÑ€ÑˆÑ‘Ð½")
